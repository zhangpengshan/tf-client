// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/rewriter_config.proto

package org.tensorflow.framework;

/**
 * <pre>
 * Graph rewriting is experimental and subject to change, not covered by any
 * API stability guarantees.
 * </pre>
 *
 * Protobuf type {@code tensorflow.RewriterConfig}
 */
public  final class RewriterConfig extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:tensorflow.RewriterConfig)
    RewriterConfigOrBuilder {
  // Use RewriterConfig.newBuilder() to construct.
  private RewriterConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private RewriterConfig() {
    optimizeTensorLayout_ = false;
    constantFolding_ = 0;
    arithmeticOptimization_ = 0;
    disableModelPruning_ = false;
    memoryOptimization_ = 0;
    memoryOptimizerTargetNodeNamePrefix_ = "";
    optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
  }
  private RewriterConfig(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    int mutable_bitField0_ = 0;
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          default: {
            if (!input.skipField(tag)) {
              done = true;
            }
            break;
          }
          case 8: {

            optimizeTensorLayout_ = input.readBool();
            break;
          }
          case 16: {

            disableModelPruning_ = input.readBool();
            break;
          }
          case 24: {
            int rawValue = input.readEnum();

            constantFolding_ = rawValue;
            break;
          }
          case 32: {
            int rawValue = input.readEnum();

            memoryOptimization_ = rawValue;
            break;
          }
          case 42: {
            org.tensorflow.framework.AutoParallelOptions.Builder subBuilder = null;
            if (autoParallel_ != null) {
              subBuilder = autoParallel_.toBuilder();
            }
            autoParallel_ = input.readMessage(org.tensorflow.framework.AutoParallelOptions.parser(), extensionRegistry);
            if (subBuilder != null) {
              subBuilder.mergeFrom(autoParallel_);
              autoParallel_ = subBuilder.buildPartial();
            }

            break;
          }
          case 50: {
            java.lang.String s = input.readStringRequireUtf8();

            memoryOptimizerTargetNodeNamePrefix_ = s;
            break;
          }
          case 56: {
            int rawValue = input.readEnum();

            arithmeticOptimization_ = rawValue;
            break;
          }
          case 802: {
            java.lang.String s = input.readStringRequireUtf8();
            if (!((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
              optimizers_ = new com.google.protobuf.LazyStringArrayList();
              mutable_bitField0_ |= 0x00000080;
            }
            optimizers_.add(s);
            break;
          }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(
          e).setUnfinishedMessage(this);
    } finally {
      if (((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
        optimizers_ = optimizers_.getUnmodifiableView();
      }
      makeExtensionsImmutable();
    }
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
  }

  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.tensorflow.framework.RewriterConfig.class, org.tensorflow.framework.RewriterConfig.Builder.class);
  }

  /**
   * Protobuf enum {@code tensorflow.RewriterConfig.Toggle}
   */
  public enum Toggle
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DEFAULT = 0;</code>
     */
    DEFAULT(0),
    /**
     * <code>ON = 1;</code>
     */
    ON(1),
    /**
     * <code>OFF = 2;</code>
     */
    OFF(2),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>DEFAULT = 0;</code>
     */
    public static final int DEFAULT_VALUE = 0;
    /**
     * <code>ON = 1;</code>
     */
    public static final int ON_VALUE = 1;
    /**
     * <code>OFF = 2;</code>
     */
    public static final int OFF_VALUE = 2;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Toggle valueOf(int value) {
      return forNumber(value);
    }

    public static Toggle forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT;
        case 1: return ON;
        case 2: return OFF;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<Toggle>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        Toggle> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<Toggle>() {
            public Toggle findValueByNumber(int number) {
              return Toggle.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfig.getDescriptor().getEnumTypes().get(0);
    }

    private static final Toggle[] VALUES = values();

    public static Toggle valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Toggle(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.Toggle)
  }

  /**
   * Protobuf enum {@code tensorflow.RewriterConfig.MemOptType}
   */
  public enum MemOptType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * The default setting (currently disabled)
     * </pre>
     *
     * <code>DEFAULT_MEM_OPT = 0;</code>
     */
    DEFAULT_MEM_OPT(0),
    /**
     * <pre>
     * Disabled in the meta-optimizer.
     * </pre>
     *
     * <code>NO_MEM_OPT = 1;</code>
     */
    NO_MEM_OPT(1),
    /**
     * <pre>
     * Driven by manual op-level annotations.
     * </pre>
     *
     * <code>MANUAL = 2;</code>
     */
    MANUAL(2),
    /**
     * <pre>
     * Driven by heuristics. The behavior of these heuristics is subject to
     * change. Currently includes an experimental recomputation
     * heuristic. Manual annotations are respected, but additional nodes are
     * selected automatically.
     * </pre>
     *
     * <code>HEURISTICS = 3;</code>
     */
    HEURISTICS(3),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * The default setting (currently disabled)
     * </pre>
     *
     * <code>DEFAULT_MEM_OPT = 0;</code>
     */
    public static final int DEFAULT_MEM_OPT_VALUE = 0;
    /**
     * <pre>
     * Disabled in the meta-optimizer.
     * </pre>
     *
     * <code>NO_MEM_OPT = 1;</code>
     */
    public static final int NO_MEM_OPT_VALUE = 1;
    /**
     * <pre>
     * Driven by manual op-level annotations.
     * </pre>
     *
     * <code>MANUAL = 2;</code>
     */
    public static final int MANUAL_VALUE = 2;
    /**
     * <pre>
     * Driven by heuristics. The behavior of these heuristics is subject to
     * change. Currently includes an experimental recomputation
     * heuristic. Manual annotations are respected, but additional nodes are
     * selected automatically.
     * </pre>
     *
     * <code>HEURISTICS = 3;</code>
     */
    public static final int HEURISTICS_VALUE = 3;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MemOptType valueOf(int value) {
      return forNumber(value);
    }

    public static MemOptType forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT_MEM_OPT;
        case 1: return NO_MEM_OPT;
        case 2: return MANUAL;
        case 3: return HEURISTICS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<MemOptType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        MemOptType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<MemOptType>() {
            public MemOptType findValueByNumber(int number) {
              return MemOptType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfig.getDescriptor().getEnumTypes().get(1);
    }

    private static final MemOptType[] VALUES = values();

    public static MemOptType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MemOptType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.MemOptType)
  }

  private int bitField0_;
  public static final int OPTIMIZE_TENSOR_LAYOUT_FIELD_NUMBER = 1;
  private boolean optimizeTensorLayout_;
  /**
   * <pre>
   * Optimize tensor layouts
   * </pre>
   *
   * <code>optional bool optimize_tensor_layout = 1;</code>
   */
  public boolean getOptimizeTensorLayout() {
    return optimizeTensorLayout_;
  }

  public static final int CONSTANT_FOLDING_FIELD_NUMBER = 3;
  private int constantFolding_;
  /**
   * <pre>
   * Fold constants (default is ON)
   * </pre>
   *
   * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
   */
  public int getConstantFoldingValue() {
    return constantFolding_;
  }
  /**
   * <pre>
   * Fold constants (default is ON)
   * </pre>
   *
   * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getConstantFolding() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(constantFolding_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int ARITHMETIC_OPTIMIZATION_FIELD_NUMBER = 7;
  private int arithmeticOptimization_;
  /**
   * <pre>
   * Arithmetic optimizations (default is ON)
   * </pre>
   *
   * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
   */
  public int getArithmeticOptimizationValue() {
    return arithmeticOptimization_;
  }
  /**
   * <pre>
   * Arithmetic optimizations (default is ON)
   * </pre>
   *
   * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
   */
  public org.tensorflow.framework.RewriterConfig.Toggle getArithmeticOptimization() {
    org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(arithmeticOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DISABLE_MODEL_PRUNING_FIELD_NUMBER = 2;
  private boolean disableModelPruning_;
  /**
   * <pre>
   * If true, don't remove unnecessary ops from the graph
   * </pre>
   *
   * <code>optional bool disable_model_pruning = 2;</code>
   */
  public boolean getDisableModelPruning() {
    return disableModelPruning_;
  }

  public static final int MEMORY_OPTIMIZATION_FIELD_NUMBER = 4;
  private int memoryOptimization_;
  /**
   * <pre>
   * Configures memory optimization passes through the meta-optimizer. Has no
   * effect on manually requested memory optimization passes in the optimizers
   * field.
   * </pre>
   *
   * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
   */
  public int getMemoryOptimizationValue() {
    return memoryOptimization_;
  }
  /**
   * <pre>
   * Configures memory optimization passes through the meta-optimizer. Has no
   * effect on manually requested memory optimization passes in the optimizers
   * field.
   * </pre>
   *
   * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
   */
  public org.tensorflow.framework.RewriterConfig.MemOptType getMemoryOptimization() {
    org.tensorflow.framework.RewriterConfig.MemOptType result = org.tensorflow.framework.RewriterConfig.MemOptType.valueOf(memoryOptimization_);
    return result == null ? org.tensorflow.framework.RewriterConfig.MemOptType.UNRECOGNIZED : result;
  }

  public static final int MEMORY_OPTIMIZER_TARGET_NODE_NAME_PREFIX_FIELD_NUMBER = 6;
  private volatile java.lang.Object memoryOptimizerTargetNodeNamePrefix_;
  /**
   * <pre>
   * The prefix for nodes which are valid outputs of recomputations. Inputs to
   * nodes with this name prefix may be recomputed (subject either to manual
   * annotation of those input nodes or to manual annotation and heuristics
   * depending on memory_optimization), but the prefixed nodes themselves will
   * not be recomputed. Typically this will be "gradients/", indicating that
   * activations from the forward pass of a graph may be recomputed as inputs to
   * gradients, but may be adjusted if gradients are inside a name scope or if
   * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
   * empty or not set.
   * </pre>
   *
   * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
   */
  public java.lang.String getMemoryOptimizerTargetNodeNamePrefix() {
    java.lang.Object ref = memoryOptimizerTargetNodeNamePrefix_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      memoryOptimizerTargetNodeNamePrefix_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * The prefix for nodes which are valid outputs of recomputations. Inputs to
   * nodes with this name prefix may be recomputed (subject either to manual
   * annotation of those input nodes or to manual annotation and heuristics
   * depending on memory_optimization), but the prefixed nodes themselves will
   * not be recomputed. Typically this will be "gradients/", indicating that
   * activations from the forward pass of a graph may be recomputed as inputs to
   * gradients, but may be adjusted if gradients are inside a name scope or if
   * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
   * empty or not set.
   * </pre>
   *
   * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
   */
  public com.google.protobuf.ByteString
      getMemoryOptimizerTargetNodeNamePrefixBytes() {
    java.lang.Object ref = memoryOptimizerTargetNodeNamePrefix_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      memoryOptimizerTargetNodeNamePrefix_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int AUTO_PARALLEL_FIELD_NUMBER = 5;
  private org.tensorflow.framework.AutoParallelOptions autoParallel_;
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  public boolean hasAutoParallel() {
    return autoParallel_ != null;
  }
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  public org.tensorflow.framework.AutoParallelOptions getAutoParallel() {
    return autoParallel_ == null ? org.tensorflow.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
  }
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  public org.tensorflow.framework.AutoParallelOptionsOrBuilder getAutoParallelOrBuilder() {
    return getAutoParallel();
  }

  public static final int OPTIMIZERS_FIELD_NUMBER = 100;
  private com.google.protobuf.LazyStringList optimizers_;
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public com.google.protobuf.ProtocolStringList
      getOptimizersList() {
    return optimizers_;
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public int getOptimizersCount() {
    return optimizers_.size();
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public java.lang.String getOptimizers(int index) {
    return optimizers_.get(index);
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   */
  public com.google.protobuf.ByteString
      getOptimizersBytes(int index) {
    return optimizers_.getByteString(index);
  }

  private byte memoizedIsInitialized = -1;
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (optimizeTensorLayout_ != false) {
      output.writeBool(1, optimizeTensorLayout_);
    }
    if (disableModelPruning_ != false) {
      output.writeBool(2, disableModelPruning_);
    }
    if (constantFolding_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(3, constantFolding_);
    }
    if (memoryOptimization_ != org.tensorflow.framework.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.getNumber()) {
      output.writeEnum(4, memoryOptimization_);
    }
    if (autoParallel_ != null) {
      output.writeMessage(5, getAutoParallel());
    }
    if (!getMemoryOptimizerTargetNodeNamePrefixBytes().isEmpty()) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 6, memoryOptimizerTargetNodeNamePrefix_);
    }
    if (arithmeticOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(7, arithmeticOptimization_);
    }
    for (int i = 0; i < optimizers_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 100, optimizers_.getRaw(i));
    }
  }

  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (optimizeTensorLayout_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(1, optimizeTensorLayout_);
    }
    if (disableModelPruning_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(2, disableModelPruning_);
    }
    if (constantFolding_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(3, constantFolding_);
    }
    if (memoryOptimization_ != org.tensorflow.framework.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(4, memoryOptimization_);
    }
    if (autoParallel_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(5, getAutoParallel());
    }
    if (!getMemoryOptimizerTargetNodeNamePrefixBytes().isEmpty()) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, memoryOptimizerTargetNodeNamePrefix_);
    }
    if (arithmeticOptimization_ != org.tensorflow.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(7, arithmeticOptimization_);
    }
    {
      int dataSize = 0;
      for (int i = 0; i < optimizers_.size(); i++) {
        dataSize += computeStringSizeNoTag(optimizers_.getRaw(i));
      }
      size += dataSize;
      size += 2 * getOptimizersList().size();
    }
    memoizedSize = size;
    return size;
  }

  private static final long serialVersionUID = 0L;
  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.tensorflow.framework.RewriterConfig)) {
      return super.equals(obj);
    }
    org.tensorflow.framework.RewriterConfig other = (org.tensorflow.framework.RewriterConfig) obj;

    boolean result = true;
    result = result && (getOptimizeTensorLayout()
        == other.getOptimizeTensorLayout());
    result = result && constantFolding_ == other.constantFolding_;
    result = result && arithmeticOptimization_ == other.arithmeticOptimization_;
    result = result && (getDisableModelPruning()
        == other.getDisableModelPruning());
    result = result && memoryOptimization_ == other.memoryOptimization_;
    result = result && getMemoryOptimizerTargetNodeNamePrefix()
        .equals(other.getMemoryOptimizerTargetNodeNamePrefix());
    result = result && (hasAutoParallel() == other.hasAutoParallel());
    if (hasAutoParallel()) {
      result = result && getAutoParallel()
          .equals(other.getAutoParallel());
    }
    result = result && getOptimizersList()
        .equals(other.getOptimizersList());
    return result;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptorForType().hashCode();
    hash = (37 * hash) + OPTIMIZE_TENSOR_LAYOUT_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getOptimizeTensorLayout());
    hash = (37 * hash) + CONSTANT_FOLDING_FIELD_NUMBER;
    hash = (53 * hash) + constantFolding_;
    hash = (37 * hash) + ARITHMETIC_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + arithmeticOptimization_;
    hash = (37 * hash) + DISABLE_MODEL_PRUNING_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getDisableModelPruning());
    hash = (37 * hash) + MEMORY_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + memoryOptimization_;
    hash = (37 * hash) + MEMORY_OPTIMIZER_TARGET_NODE_NAME_PREFIX_FIELD_NUMBER;
    hash = (53 * hash) + getMemoryOptimizerTargetNodeNamePrefix().hashCode();
    if (hasAutoParallel()) {
      hash = (37 * hash) + AUTO_PARALLEL_FIELD_NUMBER;
      hash = (53 * hash) + getAutoParallel().hashCode();
    }
    if (getOptimizersCount() > 0) {
      hash = (37 * hash) + OPTIMIZERS_FIELD_NUMBER;
      hash = (53 * hash) + getOptimizersList().hashCode();
    }
    hash = (29 * hash) + unknownFields.hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static org.tensorflow.framework.RewriterConfig parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.tensorflow.framework.RewriterConfig parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.tensorflow.framework.RewriterConfig prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Graph rewriting is experimental and subject to change, not covered by any
   * API stability guarantees.
   * </pre>
   *
   * Protobuf type {@code tensorflow.RewriterConfig}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:tensorflow.RewriterConfig)
      org.tensorflow.framework.RewriterConfigOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.tensorflow.framework.RewriterConfig.class, org.tensorflow.framework.RewriterConfig.Builder.class);
    }

    // Construct using org.tensorflow.framework.RewriterConfig.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3
              .alwaysUseFieldBuilders) {
      }
    }
    public Builder clear() {
      super.clear();
      optimizeTensorLayout_ = false;

      constantFolding_ = 0;

      arithmeticOptimization_ = 0;

      disableModelPruning_ = false;

      memoryOptimization_ = 0;

      memoryOptimizerTargetNodeNamePrefix_ = "";

      if (autoParallelBuilder_ == null) {
        autoParallel_ = null;
      } else {
        autoParallel_ = null;
        autoParallelBuilder_ = null;
      }
      optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000080);
      return this;
    }

    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.tensorflow.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
    }

    public org.tensorflow.framework.RewriterConfig getDefaultInstanceForType() {
      return org.tensorflow.framework.RewriterConfig.getDefaultInstance();
    }

    public org.tensorflow.framework.RewriterConfig build() {
      org.tensorflow.framework.RewriterConfig result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    public org.tensorflow.framework.RewriterConfig buildPartial() {
      org.tensorflow.framework.RewriterConfig result = new org.tensorflow.framework.RewriterConfig(this);
      int from_bitField0_ = bitField0_;
      int to_bitField0_ = 0;
      result.optimizeTensorLayout_ = optimizeTensorLayout_;
      result.constantFolding_ = constantFolding_;
      result.arithmeticOptimization_ = arithmeticOptimization_;
      result.disableModelPruning_ = disableModelPruning_;
      result.memoryOptimization_ = memoryOptimization_;
      result.memoryOptimizerTargetNodeNamePrefix_ = memoryOptimizerTargetNodeNamePrefix_;
      if (autoParallelBuilder_ == null) {
        result.autoParallel_ = autoParallel_;
      } else {
        result.autoParallel_ = autoParallelBuilder_.build();
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        optimizers_ = optimizers_.getUnmodifiableView();
        bitField0_ = (bitField0_ & ~0x00000080);
      }
      result.optimizers_ = optimizers_;
      result.bitField0_ = to_bitField0_;
      onBuilt();
      return result;
    }

    public Builder clone() {
      return (Builder) super.clone();
    }
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return (Builder) super.setField(field, value);
    }
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return (Builder) super.clearField(field);
    }
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return (Builder) super.clearOneof(oneof);
    }
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, Object value) {
      return (Builder) super.setRepeatedField(field, index, value);
    }
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        Object value) {
      return (Builder) super.addRepeatedField(field, value);
    }
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.tensorflow.framework.RewriterConfig) {
        return mergeFrom((org.tensorflow.framework.RewriterConfig)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.tensorflow.framework.RewriterConfig other) {
      if (other == org.tensorflow.framework.RewriterConfig.getDefaultInstance()) return this;
      if (other.getOptimizeTensorLayout() != false) {
        setOptimizeTensorLayout(other.getOptimizeTensorLayout());
      }
      if (other.constantFolding_ != 0) {
        setConstantFoldingValue(other.getConstantFoldingValue());
      }
      if (other.arithmeticOptimization_ != 0) {
        setArithmeticOptimizationValue(other.getArithmeticOptimizationValue());
      }
      if (other.getDisableModelPruning() != false) {
        setDisableModelPruning(other.getDisableModelPruning());
      }
      if (other.memoryOptimization_ != 0) {
        setMemoryOptimizationValue(other.getMemoryOptimizationValue());
      }
      if (!other.getMemoryOptimizerTargetNodeNamePrefix().isEmpty()) {
        memoryOptimizerTargetNodeNamePrefix_ = other.memoryOptimizerTargetNodeNamePrefix_;
        onChanged();
      }
      if (other.hasAutoParallel()) {
        mergeAutoParallel(other.getAutoParallel());
      }
      if (!other.optimizers_.isEmpty()) {
        if (optimizers_.isEmpty()) {
          optimizers_ = other.optimizers_;
          bitField0_ = (bitField0_ & ~0x00000080);
        } else {
          ensureOptimizersIsMutable();
          optimizers_.addAll(other.optimizers_);
        }
        onChanged();
      }
      onChanged();
      return this;
    }

    public final boolean isInitialized() {
      return true;
    }

    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      org.tensorflow.framework.RewriterConfig parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (org.tensorflow.framework.RewriterConfig) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }
    private int bitField0_;

    private boolean optimizeTensorLayout_ ;
    /**
     * <pre>
     * Optimize tensor layouts
     * </pre>
     *
     * <code>optional bool optimize_tensor_layout = 1;</code>
     */
    public boolean getOptimizeTensorLayout() {
      return optimizeTensorLayout_;
    }
    /**
     * <pre>
     * Optimize tensor layouts
     * </pre>
     *
     * <code>optional bool optimize_tensor_layout = 1;</code>
     */
    public Builder setOptimizeTensorLayout(boolean value) {
      
      optimizeTensorLayout_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize tensor layouts
     * </pre>
     *
     * <code>optional bool optimize_tensor_layout = 1;</code>
     */
    public Builder clearOptimizeTensorLayout() {
      
      optimizeTensorLayout_ = false;
      onChanged();
      return this;
    }

    private int constantFolding_ = 0;
    /**
     * <pre>
     * Fold constants (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public int getConstantFoldingValue() {
      return constantFolding_;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public Builder setConstantFoldingValue(int value) {
      constantFolding_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getConstantFolding() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(constantFolding_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public Builder setConstantFolding(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      constantFolding_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     */
    public Builder clearConstantFolding() {
      
      constantFolding_ = 0;
      onChanged();
      return this;
    }

    private int arithmeticOptimization_ = 0;
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public int getArithmeticOptimizationValue() {
      return arithmeticOptimization_;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public Builder setArithmeticOptimizationValue(int value) {
      arithmeticOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public org.tensorflow.framework.RewriterConfig.Toggle getArithmeticOptimization() {
      org.tensorflow.framework.RewriterConfig.Toggle result = org.tensorflow.framework.RewriterConfig.Toggle.valueOf(arithmeticOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public Builder setArithmeticOptimization(org.tensorflow.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      arithmeticOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     */
    public Builder clearArithmeticOptimization() {
      
      arithmeticOptimization_ = 0;
      onChanged();
      return this;
    }

    private boolean disableModelPruning_ ;
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>optional bool disable_model_pruning = 2;</code>
     */
    public boolean getDisableModelPruning() {
      return disableModelPruning_;
    }
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>optional bool disable_model_pruning = 2;</code>
     */
    public Builder setDisableModelPruning(boolean value) {
      
      disableModelPruning_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>optional bool disable_model_pruning = 2;</code>
     */
    public Builder clearDisableModelPruning() {
      
      disableModelPruning_ = false;
      onChanged();
      return this;
    }

    private int memoryOptimization_ = 0;
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public int getMemoryOptimizationValue() {
      return memoryOptimization_;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public Builder setMemoryOptimizationValue(int value) {
      memoryOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public org.tensorflow.framework.RewriterConfig.MemOptType getMemoryOptimization() {
      org.tensorflow.framework.RewriterConfig.MemOptType result = org.tensorflow.framework.RewriterConfig.MemOptType.valueOf(memoryOptimization_);
      return result == null ? org.tensorflow.framework.RewriterConfig.MemOptType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public Builder setMemoryOptimization(org.tensorflow.framework.RewriterConfig.MemOptType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      memoryOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>optional .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     */
    public Builder clearMemoryOptimization() {
      
      memoryOptimization_ = 0;
      onChanged();
      return this;
    }

    private java.lang.Object memoryOptimizerTargetNodeNamePrefix_ = "";
    /**
     * <pre>
     * The prefix for nodes which are valid outputs of recomputations. Inputs to
     * nodes with this name prefix may be recomputed (subject either to manual
     * annotation of those input nodes or to manual annotation and heuristics
     * depending on memory_optimization), but the prefixed nodes themselves will
     * not be recomputed. Typically this will be "gradients/", indicating that
     * activations from the forward pass of a graph may be recomputed as inputs to
     * gradients, but may be adjusted if gradients are inside a name scope or if
     * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
     * empty or not set.
     * </pre>
     *
     * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
     */
    public java.lang.String getMemoryOptimizerTargetNodeNamePrefix() {
      java.lang.Object ref = memoryOptimizerTargetNodeNamePrefix_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        memoryOptimizerTargetNodeNamePrefix_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * The prefix for nodes which are valid outputs of recomputations. Inputs to
     * nodes with this name prefix may be recomputed (subject either to manual
     * annotation of those input nodes or to manual annotation and heuristics
     * depending on memory_optimization), but the prefixed nodes themselves will
     * not be recomputed. Typically this will be "gradients/", indicating that
     * activations from the forward pass of a graph may be recomputed as inputs to
     * gradients, but may be adjusted if gradients are inside a name scope or if
     * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
     * empty or not set.
     * </pre>
     *
     * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
     */
    public com.google.protobuf.ByteString
        getMemoryOptimizerTargetNodeNamePrefixBytes() {
      java.lang.Object ref = memoryOptimizerTargetNodeNamePrefix_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        memoryOptimizerTargetNodeNamePrefix_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * The prefix for nodes which are valid outputs of recomputations. Inputs to
     * nodes with this name prefix may be recomputed (subject either to manual
     * annotation of those input nodes or to manual annotation and heuristics
     * depending on memory_optimization), but the prefixed nodes themselves will
     * not be recomputed. Typically this will be "gradients/", indicating that
     * activations from the forward pass of a graph may be recomputed as inputs to
     * gradients, but may be adjusted if gradients are inside a name scope or if
     * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
     * empty or not set.
     * </pre>
     *
     * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
     */
    public Builder setMemoryOptimizerTargetNodeNamePrefix(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      memoryOptimizerTargetNodeNamePrefix_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * The prefix for nodes which are valid outputs of recomputations. Inputs to
     * nodes with this name prefix may be recomputed (subject either to manual
     * annotation of those input nodes or to manual annotation and heuristics
     * depending on memory_optimization), but the prefixed nodes themselves will
     * not be recomputed. Typically this will be "gradients/", indicating that
     * activations from the forward pass of a graph may be recomputed as inputs to
     * gradients, but may be adjusted if gradients are inside a name scope or if
     * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
     * empty or not set.
     * </pre>
     *
     * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
     */
    public Builder clearMemoryOptimizerTargetNodeNamePrefix() {
      
      memoryOptimizerTargetNodeNamePrefix_ = getDefaultInstance().getMemoryOptimizerTargetNodeNamePrefix();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * The prefix for nodes which are valid outputs of recomputations. Inputs to
     * nodes with this name prefix may be recomputed (subject either to manual
     * annotation of those input nodes or to manual annotation and heuristics
     * depending on memory_optimization), but the prefixed nodes themselves will
     * not be recomputed. Typically this will be "gradients/", indicating that
     * activations from the forward pass of a graph may be recomputed as inputs to
     * gradients, but may be adjusted if gradients are inside a name scope or if
     * inputs to non-gradients should be recomputed. Defaults to "gradients/" if
     * empty or not set.
     * </pre>
     *
     * <code>optional string memory_optimizer_target_node_name_prefix = 6;</code>
     */
    public Builder setMemoryOptimizerTargetNodeNamePrefixBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      memoryOptimizerTargetNodeNamePrefix_ = value;
      onChanged();
      return this;
    }

    private org.tensorflow.framework.AutoParallelOptions autoParallel_ = null;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.framework.AutoParallelOptions, org.tensorflow.framework.AutoParallelOptions.Builder, org.tensorflow.framework.AutoParallelOptionsOrBuilder> autoParallelBuilder_;
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public boolean hasAutoParallel() {
      return autoParallelBuilder_ != null || autoParallel_ != null;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.framework.AutoParallelOptions getAutoParallel() {
      if (autoParallelBuilder_ == null) {
        return autoParallel_ == null ? org.tensorflow.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
      } else {
        return autoParallelBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder setAutoParallel(org.tensorflow.framework.AutoParallelOptions value) {
      if (autoParallelBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        autoParallel_ = value;
        onChanged();
      } else {
        autoParallelBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder setAutoParallel(
        org.tensorflow.framework.AutoParallelOptions.Builder builderForValue) {
      if (autoParallelBuilder_ == null) {
        autoParallel_ = builderForValue.build();
        onChanged();
      } else {
        autoParallelBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder mergeAutoParallel(org.tensorflow.framework.AutoParallelOptions value) {
      if (autoParallelBuilder_ == null) {
        if (autoParallel_ != null) {
          autoParallel_ =
            org.tensorflow.framework.AutoParallelOptions.newBuilder(autoParallel_).mergeFrom(value).buildPartial();
        } else {
          autoParallel_ = value;
        }
        onChanged();
      } else {
        autoParallelBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder clearAutoParallel() {
      if (autoParallelBuilder_ == null) {
        autoParallel_ = null;
        onChanged();
      } else {
        autoParallel_ = null;
        autoParallelBuilder_ = null;
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.framework.AutoParallelOptions.Builder getAutoParallelBuilder() {
      
      onChanged();
      return getAutoParallelFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.framework.AutoParallelOptionsOrBuilder getAutoParallelOrBuilder() {
      if (autoParallelBuilder_ != null) {
        return autoParallelBuilder_.getMessageOrBuilder();
      } else {
        return autoParallel_ == null ?
            org.tensorflow.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
      }
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>optional .tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.framework.AutoParallelOptions, org.tensorflow.framework.AutoParallelOptions.Builder, org.tensorflow.framework.AutoParallelOptionsOrBuilder> 
        getAutoParallelFieldBuilder() {
      if (autoParallelBuilder_ == null) {
        autoParallelBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.tensorflow.framework.AutoParallelOptions, org.tensorflow.framework.AutoParallelOptions.Builder, org.tensorflow.framework.AutoParallelOptionsOrBuilder>(
                getAutoParallel(),
                getParentForChildren(),
                isClean());
        autoParallel_ = null;
      }
      return autoParallelBuilder_;
    }

    private com.google.protobuf.LazyStringList optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    private void ensureOptimizersIsMutable() {
      if (!((bitField0_ & 0x00000080) == 0x00000080)) {
        optimizers_ = new com.google.protobuf.LazyStringArrayList(optimizers_);
        bitField0_ |= 0x00000080;
       }
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getOptimizersList() {
      return optimizers_.getUnmodifiableView();
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public int getOptimizersCount() {
      return optimizers_.size();
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public java.lang.String getOptimizers(int index) {
      return optimizers_.get(index);
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public com.google.protobuf.ByteString
        getOptimizersBytes(int index) {
      return optimizers_.getByteString(index);
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder setOptimizers(
        int index, java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  ensureOptimizersIsMutable();
      optimizers_.set(index, value);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder addOptimizers(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  ensureOptimizersIsMutable();
      optimizers_.add(value);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder addAllOptimizers(
        java.lang.Iterable<java.lang.String> values) {
      ensureOptimizersIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(
          values, optimizers_);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder clearOptimizers() {
      optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000080);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     */
    public Builder addOptimizersBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      ensureOptimizersIsMutable();
      optimizers_.add(value);
      onChanged();
      return this;
    }
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }

    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }


    // @@protoc_insertion_point(builder_scope:tensorflow.RewriterConfig)
  }

  // @@protoc_insertion_point(class_scope:tensorflow.RewriterConfig)
  private static final org.tensorflow.framework.RewriterConfig DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.tensorflow.framework.RewriterConfig();
  }

  public static org.tensorflow.framework.RewriterConfig getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<RewriterConfig>
      PARSER = new com.google.protobuf.AbstractParser<RewriterConfig>() {
    public RewriterConfig parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
        return new RewriterConfig(input, extensionRegistry);
    }
  };

  public static com.google.protobuf.Parser<RewriterConfig> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<RewriterConfig> getParserForType() {
    return PARSER;
  }

  public org.tensorflow.framework.RewriterConfig getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

